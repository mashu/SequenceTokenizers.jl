var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = SequenceTokenizers","category":"page"},{"location":"#SequenceTokenizers","page":"Home","title":"SequenceTokenizers","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for SequenceTokenizers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [SequenceTokenizers]","category":"page"},{"location":"#SequenceTokenizers.SequenceTokenizers","page":"Home","title":"SequenceTokenizers.SequenceTokenizers","text":"SequenceTokenizers\n\nA module for tokenizing sequences of symbols into numerical indices and vice versa. This module provides functionality for creating tokenizers, encoding sequences, and working with one-hot representations of tokenized data.\n\nExports\n\nSequenceTokenizer: A struct for tokenizing sequences\nonehot_batch: Convert tokenized sequences to one-hot representations\nonecold_batch: Convert one-hot representations back to tokenized sequences\n\nExample\n\nusing SequenceTokenizers\n\n# Create a tokenizer for DNA sequences\ndna_alphabet = ['A', 'C', 'G', 'T']\ntokenizer = SequenceTokenizer(dna_alphabet, 'N')\n\n# Tokenize a sequence\nseq = \"ACGTACGT\"\ntokenized = tokenizer(seq)\n\n# Convert to one-hot representation\nonehot = onehot_batch(tokenizer, tokenized)\n\n# Convert back to tokens\nrecovered = onecold_batch(tokenizer, onehot)\n\n\n\n\n\n","category":"module"},{"location":"#SequenceTokenizers.SequenceTokenizer","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"SequenceTokenizer{T, V <: AbstractVector{T}}\n\nA struct for tokenizing sequences of symbols into numerical indices.\n\nFields\n\nalphabet::V: The set of valid symbols in the sequences\nlookup::Vector{Int32}: A lookup table for fast symbol-to-index conversion\nunksym::T: The symbol to use for unknown tokens\nunkidx::Int32: The index assigned to the unknown symbol\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\n\n\n\n\n\n","category":"type"},{"location":"#SequenceTokenizers.SequenceTokenizer-Tuple{Integer}","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer)(idx::Integer)\n\nConvert an index back to its corresponding token.\n\nArguments\n\nidx::Integer: An index to be converted back to a token\n\nReturns\n\nThe token corresponding to the given index in the tokenizer's alphabet\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nprintln(tokenizer(2))  # Output: 'a'\nprintln(tokenizer(1))  # Output: 'x' (unknown token)\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.SequenceTokenizer-Tuple{T} where T","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer{T})(token::T) where T\n\nConvert a single token to its corresponding index.\n\nArguments\n\ntoken::T: A single token to be converted to an index\n\nReturns\n\nThe index of the token in the tokenizer's alphabet, or the unknown token index if not found\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nprintln(tokenizer('a'))  # Output: 2\nprintln(tokenizer('x'))  # Output: 1\nprintln(tokenizer('z'))  # Output: 1 (unknown token)\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.SequenceTokenizer-Union{Tuple{AbstractArray}, Tuple{T}} where T","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer{T})(x::AbstractArray) where T\n\nTokenize an array of symbols.\n\nArguments\n\nx::AbstractArray: An array of symbols to be tokenized\n\nReturns\n\nAn array of indices corresponding to the input symbols\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nprintln(tokenizer(['a', 'b', 'z', 'c']))  # Output: [2, 3, 1, 4]\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.SequenceTokenizer-Union{Tuple{AbstractString}, Tuple{T}} where T","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer{T})(input::AbstractString) where T\n\nTokenize a string input using the SequenceTokenizer.\n\nThis method efficiently converts the input string to a vector of tokens of type T and applies the tokenizer to each element.\n\nArguments\n\ntokenizer::SequenceTokenizer{T}: The tokenizer to use\ninput::AbstractString: The input string to be tokenized\n\nReturns\n\nA Vector{Int32} of token indices corresponding to the characters in the input string\n\nPerformance Notes\n\nThis method uses collect(T, input) to convert the string to a vector of type T\nIt's marked as @inline for potential performance benefits in certain contexts\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nresult = tokenizer(\"abcx\")\nprintln(result)  # Output: [2, 3, 4, 1]\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.SequenceTokenizer-Union{Tuple{AbstractVector{<:AbstractString}}, Tuple{T}} where T","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer{T})(batch::AbstractVector{<:AbstractString}) where T\n\nTokenize a batch of string sequences, padding shorter sequences with the unknown token.\n\nArguments\n\ntokenizer::SequenceTokenizer{T}: The tokenizer to use\nbatch::AbstractVector{<:AbstractString}: A vector of string sequences to be tokenized\n\nReturns\n\nA matrix of indices, where each column represents a tokenized and padded sequence\n\nExample\n\ntokenizer = SequenceTokenizer(['A','T','G','C'], 'N')\nsequences = [\"ATG\", \"ATGCGC\"]\nresult = tokenizer(sequences)\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.SequenceTokenizer-Union{Tuple{AbstractVector{<:AbstractVector{T}}}, Tuple{T}} where T","page":"Home","title":"SequenceTokenizers.SequenceTokenizer","text":"(tokenizer::SequenceTokenizer{T})(batch::AbstractVector{<:AbstractVector{T}}) where T\n\nTokenize a batch of sequences, padding shorter sequences with the unknown token.\n\nArguments\n\nbatch::AbstractVector{<:AbstractVector{T}}: A vector of sequences to be tokenized\n\nReturns\n\nA matrix of indices, where each column represents a tokenized and padded sequence\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nsequences = [['a', 'b'], ['c', 'a', 'b']]\nprintln(tokenizer(sequences))\n# Output:\n# [2 4\n#  3 2\n#  1 3]\n\n\n\n\n\n","category":"method"},{"location":"#Base.length-Tuple{SequenceTokenizer}","page":"Home","title":"Base.length","text":"Base.length(tokenizer::SequenceTokenizer)\n\nGet the number of unique tokens in the tokenizer's alphabet.\n\nReturns\n\nThe length of the tokenizer's alphabet\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nprintln(length(tokenizer))  # Output: 4\n\n\n\n\n\n","category":"method"},{"location":"#Base.show-Union{Tuple{T}, Tuple{IO, SequenceTokenizer{T, V} where V<:AbstractVector{T}}} where T","page":"Home","title":"Base.show","text":"Base.show(io::IO, tokenizer::SequenceTokenizer{T}) where T\n\nCustom display method for SequenceTokenizer instances.\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nprintln(tokenizer)  # Output: SequenceTokenizer{Char}(length(alphabet)=4, unksym=x)\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.onecold_batch-Tuple{SequenceTokenizer, OneHotArrays.OneHotArray}","page":"Home","title":"SequenceTokenizers.onecold_batch","text":"onecold_batch(tokenizer::SequenceTokenizer, onehot_batch::OneHotArray)\n\nConvert a one-hot representation back to tokenized sequences.\n\nArguments\n\ntokenizer::SequenceTokenizer: The tokenizer used for the sequences\nonehot_batch::OneHotArray: A OneHotArray representing the one-hot encoding of sequences\n\nReturns\n\nA matrix of indices representing the tokenized sequences\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nsequences = [['a', 'b'], ['c', 'a', 'b']]\ntokenized = tokenizer(sequences)\nonehot = onehot_batch(tokenizer, tokenized)\nrecovered = onecold_batch(tokenizer, onehot)\n# Recovered result is batched therefore it remains padded\nprintln(recovered == ['a' 'c'; 'b' 'a'; 'x' 'b']) # Output: true\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.onehot_batch-Tuple{SequenceTokenizer, AbstractMatrix{Int32}}","page":"Home","title":"SequenceTokenizers.onehot_batch","text":"onehot_batch(tokenizer::SequenceTokenizer, batch::AbstractMatrix{Int32})\n\nConvert a batch of tokenized sequences to one-hot representations.\n\nArguments\n\ntokenizer::SequenceTokenizer: The tokenizer used for the sequences\nbatch::AbstractMatrix{Int32}: A matrix of tokenized sequences\n\nReturns\n\nA OneHotArray representing the one-hot encoding of the input batch\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\nsequences = [[\"a\", \"b\"], [\"c\", \"a\", \"b\"]]\ntokenized = tokenizer(sequences)\nonehot = onehot_batch(tokenizer, tokenized)\nprintln(size(onehot))  # Output: (4, 3, 2)\n\n\n\n\n\n","category":"method"},{"location":"#SequenceTokenizers.onehot_batch-Tuple{SequenceTokenizer, AbstractVector{Int32}}","page":"Home","title":"SequenceTokenizers.onehot_batch","text":"onehot_batch(tokenizer::SequenceTokenizer, batch::AbstractVector{Int32})\n\nConvert a batch of tokenized sequences to one-hot representations.\n\nThis function takes a vector of token indices and converts it into a one-hot encoded representation using the alphabet of the provided tokenizer.\n\nArguments\n\ntokenizer::SequenceTokenizer: The tokenizer used for the sequences. Its length\n\ndetermines the size of the one-hot encoding dimension.\n\nbatch::AbstractVector{Int32}: A vector of token indices to be converted to\n\none-hot representation.\n\nReturns\n\nOneHotArray: A one-hot encoded representation of the input batch. The resulting\n\narray will have dimensions (length(tokenizer), length(batch)).\n\nExample\n\nalphabet = ['a', 'b', 'c']\ntokenizer = SequenceTokenizer(alphabet, 'x')\ntokenized_sequence = [2, 3, 1, 4]  # Corresponds to ['a', 'b', 'x', 'c']\nonehot = onehot_batch(tokenizer, tokenized_sequence)\nprintln(size(onehot))  # Output: (4, 4)\nprintln(onehot[:, 1])  # Output: [0, 1, 0, 0]\n\nNote\n\nThis function assumes that all indices in the input batch are valid for the tokenizer's alphabet. Indices outside the valid range may result in errors or unexpected behavior.\n\nSee also\n\nSequenceTokenizer: The tokenizer struct used to create the input batch.\nonecold_batch: The inverse operation, converting one-hot representations\n\nback to token indices.\n\n\n\n\n\n","category":"method"}]
}
